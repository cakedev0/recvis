{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import regularization as R\n",
    "from modules import NMU, NAU, LeibnizModule\n",
    "from samplers import *\n",
    "from datasets import MatrixDeterminantDataset, BatchDataLoader\n",
    "\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_until_convergence(\n",
    "    model,\n",
    "    train_loader,\n",
    "    dataset_valid_interpolation_data,\n",
    "    dataset_test_extrapolation_data,\n",
    "    regualizer_scaling_start=5000,\n",
    "    max_iter=20000,\n",
    "    alpha_scale=1.001,\n",
    "    alpha_start=0.05,\n",
    "    check_period=250,\n",
    "    lr=2e-3,\n",
    "    verbose=False\n",
    "):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    def test_model(data):\n",
    "        with torch.no_grad():\n",
    "            var, x, t = data\n",
    "            return criterion(model(x), t) / var\n",
    "    \n",
    "    for epoch_i, (var, x_train, t_train) in zip(range(1, max_iter + 1), train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        y_train = model(x_train)\n",
    "\n",
    "        if(epoch_i == regualizer_scaling_start):\n",
    "            r_w_scale = 0.01\n",
    "        elif(epoch_i > regualizer_scaling_start):\n",
    "            r_w_scale *= alpha_scale\n",
    "        else:\n",
    "            r_w_scale = 0\n",
    "            \n",
    "        muls = dict(\n",
    "            sparsity=r_w_scale,\n",
    "            n_coeffs=0\n",
    "        )\n",
    "\n",
    "        loss_train_regualizer = R.eval_regularizers(model, muls)\n",
    "        loss_train_criterion = criterion(y_train, t_train) / var\n",
    "        loss_train = loss_train_criterion + loss_train_regualizer\n",
    "        \n",
    "        if(epoch_i % check_period == 0):\n",
    "            interpolation_error = test_model(dataset_valid_interpolation_data) \n",
    "            extrapolation_error = test_model(dataset_test_extrapolation_data) \n",
    "            sparsity_loss = loss_train_regualizer.detach().cpu().numpy()\n",
    "            if(verbose):\n",
    "                infos = f\"[epoch {epoch_i}] inter: {interpolation_error:.4g}, extra: {extrapolation_error:.4g}\"\n",
    "                if(r_w_scale > 0):\n",
    "                    infos += f\" | reg: {sparsity_loss / r_w_scale:.4g} (scale: {r_w_scale:.4g})\"\n",
    "                print(infos)\n",
    "            if(r_w_scale > 0):\n",
    "                if(sparsity_loss / r_w_scale < 1e-4 and interpolation_error < 1e-3 and extrapolation_error < 1e-3):\n",
    "                    return True\n",
    "\n",
    "        \n",
    "        # Optimize model\n",
    "        if loss_train.requires_grad:\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "    return False\n",
    "\n",
    "def loaders(dataset):\n",
    "    inter_sampler = uniform(-2, 2)\n",
    "    train_loader = dataset.dataloader(batch_size=64, samplers=[inter_sampler])\n",
    "    dataset_valid_interpolation_data = next(iter(dataset.dataloader(batch_size=10000, samplers=[inter_sampler])))\n",
    "    dataset_test_extrapolation_data = next(iter(dataset.dataloader(batch_size=10000, samplers=[uniform(-4, 4)])))\n",
    "    return train_loader, dataset_valid_interpolation_data, dataset_test_extrapolation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of Leibniz module hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "MatrixDeterminantDataset for matrices of form : <br>$ \\begin{pmatrix} a_{1} & a_{2} & a_{3} & a_{4} \\\\ a_{5} & a_{6} & a_{7} & a_{8} \\\\ a_{9} & a_{10} & a_{11} & a_{12} \\\\ a_{13} & a_{14} & a_{15} & a_{16} \\end{pmatrix}$ <br>Network input is : $ \\left(a_{1} \\; a_{2} \\; a_{3} \\; a_{4} \\; a_{5} \\; a_{6} \\; a_{7} \\; a_{8} \\; a_{9} \\; a_{10} \\; a_{11} \\; a_{12} \\; a_{13} \\; a_{14} \\; a_{15} \\; a_{16}\\right)$ "
      ],
      "text/plain": [
       "<datasets.MatrixDeterminantDataset at 0x7f7c41e38690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "dataset = MatrixDeterminantDataset(ms)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da7083bd75c4bc9a8b1d2698c16e506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden size': 24, 'converged': False}\n",
      "{'hidden size': 24, 'converged': False}\n",
      "{'hidden size': 24, 'converged': False}\n",
      "{'hidden size': 24, 'converged': False}\n",
      "{'hidden size': 24, 'converged': False}\n",
      "{'hidden size': 50, 'converged': False}\n",
      "{'hidden size': 50, 'converged': False}\n",
      "{'hidden size': 50, 'converged': False}\n",
      "{'hidden size': 50, 'converged': False}\n",
      "{'hidden size': 50, 'converged': False}\n",
      "{'hidden size': 100, 'converged': True}\n",
      "{'hidden size': 100, 'converged': True}\n",
      "{'hidden size': 100, 'converged': True}\n",
      "{'hidden size': 100, 'converged': True}\n",
      "{'hidden size': 100, 'converged': True}\n",
      "{'hidden size': 200, 'converged': True}\n",
      "{'hidden size': 200, 'converged': True}\n",
      "{'hidden size': 200, 'converged': True}\n",
      "{'hidden size': 200, 'converged': True}\n",
      "{'hidden size': 200, 'converged': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "data = []\n",
    "n_repeat = 5\n",
    "hidden_sizes = [24, 50, 100, 200]\n",
    "\n",
    "with tqdm(range(len(hidden_sizes)*n_repeat)) as pbar:\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for _ in range(n_repeat):\n",
    "            model = LeibnizModule(16, hidden_size).cuda()\n",
    "            converged = train_until_convergence(\n",
    "                model,\n",
    "                *loaders(dataset),\n",
    "                regualizer_scaling_start=10000,\n",
    "                max_iter=20000)\n",
    "            data.append({\"hidden size\": hidden_size, \"converged\": converged})\n",
    "            print(data[-1])\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of sampling distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagonal_plus_two(n):\n",
    "    ms = np.zeros((n, n), dtype=int)\n",
    "    r = np.arange(n)\n",
    "    ms[r, r] = r + 1\n",
    "    ms[0, n-1] = n + 1\n",
    "    ms[n-1, 0] = n + 2\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "MatrixDeterminantDataset for matrices of form : <br>$ \\begin{pmatrix} a_{1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & a_{10} \\\\ 0 & a_{2} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & a_{3} & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & a_{4} & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & a_{5} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & a_{6} & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & a_{7} & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 0 & a_{8} & 0 \\\\ a_{11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & a_{9} \\end{pmatrix}$ <br>Network input is : $ \\left(a_{1} \\; a_{10} \\; a_{2} \\; a_{3} \\; a_{4} \\; a_{5} \\; a_{6} \\; a_{7} \\; a_{8} \\; a_{11} \\; a_{9}\\right)$ "
      ],
      "text/plain": [
       "<datasets.MatrixDeterminantDataset at 0x7f7bdc45dd10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 9\n",
    "ms = diagonal_plus_two(n)\n",
    "\n",
    "dataset = MatrixDeterminantDataset(ms, with_multiplicity=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_sampler = random_sign(one_mean_prod_sample)\n",
    "extra_sampler = one_mean_prod_sample\n",
    "\n",
    "_ = plt.hist(inter_sampler(size=100000), bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7816567084030749"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "np.mean(np.prod(one_mean_prod_sample(size=(1000, n)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 250] inter: 0.9853, extra: 2.493\n",
      "[epoch 500] inter: 0.9836, extra: 2.481\n",
      "[epoch 750] inter: 0.9814, extra: 2.05\n",
      "[epoch 1000] inter: 0.978, extra: 1.498\n",
      "[epoch 1250] inter: 0.9727, extra: 1.517\n",
      "[epoch 1500] inter: 0.9618, extra: 1.632\n",
      "[epoch 1750] inter: 0.938, extra: 1.026\n",
      "[epoch 2000] inter: 0.8883, extra: 0.7666\n",
      "[epoch 2250] inter: 0.7864, extra: 0.6987\n",
      "[epoch 2500] inter: 0.6118, extra: 0.4813\n",
      "[epoch 2750] inter: 0.4028, extra: 0.2995\n",
      "[epoch 3000] inter: 0.2335, extra: 0.2267\n",
      "[epoch 3250] inter: 0.1205, extra: 0.3184\n",
      "[epoch 3500] inter: 0.06383, extra: 0.527\n",
      "[epoch 3750] inter: 0.0365, extra: 0.5729\n",
      "[epoch 4000] inter: 0.02493, extra: 0.3784\n",
      "[epoch 4250] inter: 0.01903, extra: 0.2452\n",
      "[epoch 4500] inter: 0.0153, extra: 0.2496\n",
      "[epoch 4750] inter: 0.01266, extra: 0.1942\n",
      "[epoch 5000] inter: 0.01044, extra: 0.1048 | reg: 0.06471 (scale: 0.01)\n",
      "[epoch 5250] inter: 0.00865, extra: 0.05745 | reg: 0.0646 (scale: 0.01284)\n",
      "[epoch 5500] inter: 0.007165, extra: 0.04707 | reg: 0.0645 (scale: 0.01648)\n",
      "[epoch 5750] inter: 0.005833, extra: 0.02336 | reg: 0.06437 (scale: 0.02116)\n",
      "[epoch 6000] inter: 0.004702, extra: 0.01888 | reg: 0.0642 (scale: 0.02717)\n",
      "[epoch 6250] inter: 0.003752, extra: 0.005007 | reg: 0.06397 (scale: 0.03488)\n",
      "[epoch 6500] inter: 0.002952, extra: 0.003881 | reg: 0.06368 (scale: 0.04478)\n",
      "[epoch 6750] inter: 0.002284, extra: 0.009752 | reg: 0.06328 (scale: 0.0575)\n",
      "[epoch 7000] inter: 0.001727, extra: 0.01003 | reg: 0.06273 (scale: 0.07382)\n",
      "[epoch 7250] inter: 0.001284, extra: 0.008409 | reg: 0.06199 (scale: 0.09477)\n",
      "[epoch 7500] inter: 0.0009243, extra: 0.0054 | reg: 0.061 (scale: 0.1217)\n",
      "[epoch 7750] inter: 0.0006579, extra: 0.004438 | reg: 0.05966 (scale: 0.1562)\n",
      "[epoch 8000] inter: 0.0004616, extra: 0.004249 | reg: 0.05792 (scale: 0.2006)\n",
      "[epoch 8250] inter: 0.0003207, extra: 0.002926 | reg: 0.05571 (scale: 0.2575)\n",
      "[epoch 8500] inter: 0.0002245, extra: 0.001473 | reg: 0.05302 (scale: 0.3306)\n",
      "[epoch 8750] inter: 0.0001562, extra: 0.0008783 | reg: 0.0499 (scale: 0.4244)\n",
      "[epoch 9000] inter: 0.0001113, extra: 0.0009612 | reg: 0.04641 (scale: 0.5449)\n",
      "[epoch 9250] inter: 7.839e-05, extra: 0.001215 | reg: 0.04258 (scale: 0.6996)\n",
      "[epoch 9500] inter: 5.589e-05, extra: 0.0007181 | reg: 0.03836 (scale: 0.8981)\n",
      "[epoch 9750] inter: 3.937e-05, extra: 0.002059 | reg: 0.03374 (scale: 1.153)\n",
      "[epoch 10000] inter: 2.812e-05, extra: 0.0009608 | reg: 0.0288 (scale: 1.48)\n",
      "[epoch 10250] inter: 1.813e-05, extra: 0.0007285 | reg: 0.02377 (scale: 1.901)\n",
      "[epoch 10500] inter: 1.064e-05, extra: 0.0001946 | reg: 0.01894 (scale: 2.44)\n",
      "[epoch 10750] inter: 5.618e-06, extra: 0.0001208 | reg: 0.01457 (scale: 3.133)\n",
      "[epoch 11000] inter: 3.35e-06, extra: 1.37e-05 | reg: 0.01082 (scale: 4.022)\n",
      "[epoch 11250] inter: 3.523e-06, extra: 4.18e-06 | reg: 0.007759 (scale: 5.164)\n",
      "[epoch 11500] inter: 3.749e-06, extra: 0.0001746 | reg: 0.005366 (scale: 6.63)\n",
      "[epoch 11750] inter: 4.026e-06, extra: 0.0001674 | reg: 0.003559 (scale: 8.512)\n",
      "[epoch 12000] inter: 5.245e-06, extra: 5.141e-05 | reg: 0.00225 (scale: 10.93)\n",
      "[epoch 12250] inter: 4.458e-06, extra: 1.47e-05 | reg: 0.001347 (scale: 14.03)\n",
      "[epoch 12500] inter: 3.171e-06, extra: 3.983e-05 | reg: 0.0007573 (scale: 18.01)\n",
      "[epoch 12750] inter: 2.03e-06, extra: 0.0001096 | reg: 0.0003932 (scale: 23.13)\n",
      "[epoch 13000] inter: 1.669e-06, extra: 7.256e-05 | reg: 0.0001818 (scale: 29.69)\n",
      "[epoch 13250] inter: 1.191e-06, extra: 8.074e-05 | reg: 6.926e-05 (scale: 38.12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = dataset.dataloader(batch_size=64, samplers=[inter_sampler])\n",
    "dataset_valid_interpolation_data = next(iter(dataset.dataloader(batch_size=10000, samplers=[inter_sampler])))\n",
    "dataset_test_extrapolation_data = next(iter(dataset.dataloader(batch_size=10000, samplers=[extra_sampler])))\n",
    "\n",
    "model = LeibnizModule(n+2, 100).cuda()\n",
    "train_until_convergence(\n",
    "    model,\n",
    "    train_loader,\n",
    "    dataset_valid_interpolation_data,\n",
    "    dataset_test_extrapolation_data,\n",
    "    regualizer_scaling_start=5000,\n",
    "    verbose=True,\n",
    "    lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_sampler = uniform(-1, 1)\n",
    "extra_sampler = one_mean_prod_sample\n",
    "\n",
    "_ = plt.hist(inter_sampler(size=100000), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 500] inter: 1.205, extra: 2.447\n",
      "[epoch 1000] inter: 1.193, extra: 2.913\n",
      "[epoch 1500] inter: 1.187, extra: 2.172\n",
      "[epoch 2000] inter: 1.184, extra: 1.943\n",
      "[epoch 2500] inter: 1.181, extra: 1.923\n",
      "[epoch 3000] inter: 1.18, extra: 1.795\n",
      "[epoch 3500] inter: 1.179, extra: 1.757\n",
      "[epoch 4000] inter: 1.178, extra: 1.078\n",
      "[epoch 4500] inter: 1.175, extra: 1.196\n",
      "[epoch 5000] inter: 1.175, extra: 1.191\n",
      "[epoch 5500] inter: 1.173, extra: 1.25\n",
      "[epoch 6000] inter: 1.173, extra: 1.266\n",
      "[epoch 6500] inter: 1.173, extra: 1.208\n",
      "[epoch 7000] inter: 1.172, extra: 1.133\n",
      "[epoch 7500] inter: 1.171, extra: 1.249\n",
      "[epoch 8000] inter: 1.17, extra: 1.215\n",
      "[epoch 8500] inter: 1.171, extra: 1.073\n",
      "[epoch 9000] inter: 1.171, extra: 1.025\n",
      "[epoch 9500] inter: 1.171, extra: 1.158\n",
      "[epoch 10000] inter: 1.17, extra: 1.137 | reg: 0.06642 (scale: 0.01)\n",
      "[epoch 10500] inter: 1.17, extra: 1.007 | reg: 0.06641 (scale: 0.01648)\n",
      "[epoch 11000] inter: 1.169, extra: 1.092 | reg: 0.06639 (scale: 0.02717)\n",
      "[epoch 11500] inter: 1.17, extra: 0.9991 | reg: 0.06636 (scale: 0.04478)\n",
      "[epoch 12000] inter: 1.169, extra: 1.074 | reg: 0.06634 (scale: 0.07382)\n",
      "[epoch 12500] inter: 1.169, extra: 1.05 | reg: 0.06631 (scale: 0.1217)\n",
      "[epoch 13000] inter: 1.169, extra: 1.011 | reg: 0.06625 (scale: 0.2006)\n",
      "[epoch 13500] inter: 1.17, extra: 1.333 | reg: 0.06621 (scale: 0.3306)\n",
      "[epoch 14000] inter: 1.171, extra: 1.062 | reg: 0.06613 (scale: 0.5449)\n",
      "[epoch 14500] inter: 1.169, extra: 0.9959 | reg: 0.06604 (scale: 0.8981)\n",
      "[epoch 15000] inter: 1.169, extra: 1.08 | reg: 0.06591 (scale: 1.48)\n",
      "[epoch 15500] inter: 1.169, extra: 1.032 | reg: 0.06567 (scale: 2.44)\n",
      "[epoch 16000] inter: 1.17, extra: 1.229 | reg: 0.06527 (scale: 4.022)\n",
      "[epoch 16500] inter: 1.169, extra: 0.9781 | reg: 0.06457 (scale: 6.63)\n",
      "[epoch 17000] inter: 1.169, extra: 0.9583 | reg: 0.06339 (scale: 10.93)\n",
      "[epoch 17500] inter: 1.169, extra: 0.9862 | reg: 0.06143 (scale: 18.01)\n",
      "[epoch 18000] inter: 1.168, extra: 0.9424 | reg: 0.05857 (scale: 29.69)\n",
      "[epoch 18500] inter: 1.168, extra: 0.9456 | reg: 0.05428 (scale: 48.94)\n",
      "[epoch 19000] inter: 1.167, extra: 0.9387 | reg: 0.04873 (scale: 80.67)\n",
      "[epoch 19500] inter: 1.169, extra: 0.929 | reg: 0.04217 (scale: 133)\n",
      "[epoch 20000] inter: 1.166, extra: 0.9194 | reg: 0.03432 (scale: 219.2)\n",
      "[epoch 20500] inter: 1.163, extra: 0.9173 | reg: 0.02512 (scale: 361.3)\n",
      "[epoch 21000] inter: 1.167, extra: 0.948 | reg: 0.01591 (scale: 595.5)\n",
      "[epoch 21500] inter: 1.166, extra: 0.9603 | reg: 0.008438 (scale: 981.5)\n",
      "[epoch 22000] inter: 1.166, extra: 0.9441 | reg: 0.003641 (scale: 1618)\n",
      "[epoch 22500] inter: 1.172, extra: 0.9422 | reg: 0.001217 (scale: 2667)\n",
      "[epoch 23000] inter: 1.172, extra: 0.9474 | reg: 0.000291 (scale: 4395)\n",
      "[epoch 23500] inter: 1.17, extra: 0.9466 | reg: 4.337e-05 (scale: 7245)\n",
      "[epoch 24000] inter: 1.17, extra: 0.9545 | reg: 3.248e-06 (scale: 1.194e+04)\n",
      "[epoch 24500] inter: 1.168, extra: 0.9541 | reg: 3.292e-07 (scale: 1.968e+04)\n",
      "[epoch 25000] inter: 1.166, extra: 0.9473 | reg: 1.732e-07 (scale: 3.245e+04)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = dataset.dataloader(batch_size=64, samplers=[inter_sampler])\n",
    "dataset_valid_interpolation_data = next(iter(dataset.dataloader(batch_size=10000, samplers=[inter_sampler])))\n",
    "dataset_test_extrapolation_data = next(iter(dataset.dataloader(batch_size=10000, samplers=[extra_sampler])))\n",
    "\n",
    "model = LeibnizModule(n+2, 100).cuda()\n",
    "train_until_convergence(\n",
    "    model,\n",
    "    train_loader,\n",
    "    dataset_valid_interpolation_data,\n",
    "    dataset_test_extrapolation_data,\n",
    "    regualizer_scaling_start=10000,\n",
    "    max_iter=25000,\n",
    "    check_period=500,\n",
    "    verbose=True,\n",
    "    lr=1e-4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
